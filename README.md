# RAG with LangGraph + Google Generative AI ğŸš€

Concise demo of Retrieval-Augmented Generation (RAG) using Google Generative AI, LangChain components, FAISS, and LangGraph.

Why RAG? ğŸ¤”  
RAG improves model responses by augmenting generation with retrieved context from documents, keeping outputs accurate and grounded.

Pipeline Overview ğŸ”
1. ğŸ“„ Document Loader â€” PyPDFLoader reads PDF(s) into documents.
2. âœ‚ï¸ Splitter â€” RecursiveCharacterTextSplitter breaks documents into overlapping chunks.
3. ğŸ§  Embeddings â€” GoogleGenerativeAIEmbeddings turns chunks into vector embeddings.
4. ğŸ—„ï¸ Vector Store â€” FAISS stores the embeddings for efficient similarity search.
5. ğŸ” Retriever â€” Get the top-k similar chunks for a query.
6. ğŸ§° Tool â€” Wrap retriever in a tool (rag_tool) returning {query, context, metadata}.
7. ğŸ¤– Model With Tools â€” Bind tools to the Google GenAI model (chat + tools).
8. ğŸ•¸ï¸ Graph â€” LangGraph StateGraph orchestrates chat_node & ToolNode flow.
9. ğŸ’¬ Chat â€” Use the compiled chatbot to send HumanMessage prompts and get answers grounded in retrieved context.

Quick Setup âš™ï¸
- Python 3.10+
- Create a .env with your Google Generative API credentials (e.g., service account / API key)
- Install requirements:
  pip install -r requirements.txt
  (or install required libs: langchain_google_genai, langchain_community, langchain_core, langgraph, faiss-cpu)

How to Run (example)
1. Load env: load_dotenv()
2. Load PDF: PyPDFLoader('AI Fellowship Nepal.pdf')
3. Split: RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
4. Embed & store: FAISS.from_documents(chunks, GoogleGenerativeAIEmbeddings(...))
5. Create retriever: vectorstore.as_retriever(search_type="similarity", search_kwargs={"k":3})
6. Create rag_tool (retriever â†’ returns context & metadata)
7. Bind tool to model: model.bind_tools([rag_tool])
8. Build graph: StateGraph, ToolNode, nodes & edges, compile chatbot
9. Query: chatbot.invoke({'messages':[HumanMessage(content="Your prompt...")]})

Notes ğŸ“
- Replace model names (e.g., "gemini-2.5-flash", "gemini-embedding-001") as needed.
- Make sure to point PyPDFLoader to your PDF file path.
- Tools allow model to call the retriever during generation, enabling RAG.

License / Credits
- Example project for learning RAG with LangGraph and Google Generative AI.
